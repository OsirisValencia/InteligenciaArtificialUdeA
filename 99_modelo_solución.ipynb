{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OsirisValencia/InteligenciaArtificialUdeA/blob/main/99_modelo_soluci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbvS86QEV6U0",
        "outputId": "e773855e-61bb-47b5-d55f-7bbc106375eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 ./kaggle.json'\n",
            "usage: kaggle [-h] [-v] [-W]\n",
            "              {competitions,c,datasets,d,kernels,k,models,m,files,f,config}\n",
            "              ...\n",
            "kaggle: error: the following arguments are required: command\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '.'\n",
        "!kaggle\n",
        "!chmod 600 ./kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw8-KL05Wdpm",
        "outputId": "bf511e9f-054f-4673-915c-a07cb2148f0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading udea-ai-4-eng-20251-pruebas-saber-pro-colombia.zip to /content\n",
            "\r  0% 0.00/29.9M [00:00<?, ?B/s]\n",
            "\r100% 29.9M/29.9M [00:00<00:00, 836MB/s]\n",
            "Archive:  udea-ai-4-eng-20251-pruebas-saber-pro-colombia.zip\n",
            "  inflating: submission_example.csv  \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c udea-ai-4-eng-20251-pruebas-saber-pro-colombia\n",
        "!unzip udea-ai-4-eng-20251-pruebas-saber-pro-colombia.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import warnings\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"🚀 SOLUCIÓN ULTRA-RÁPIDA SABER PRO (LightGBM)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# ===================================================================\n",
        "# 1. CARGA Y MUESTREO AGRESIVO\n",
        "# ===================================================================\n",
        "print(\"📂 Cargando datos...\")\n",
        "dtr = pd.read_csv('train.csv')\n",
        "dts = pd.read_csv('test.csv')\n",
        "\n",
        "print(f\"Dataset original: {dtr.shape}\")\n",
        "\n",
        "# Muestreo ultra‑agresivo: solo 50k ejemplos\n",
        "print(\"⚡ Aplicando muestreo ultra-agresivo...\")\n",
        "_, dtr = train_test_split(\n",
        "    dtr,\n",
        "    test_size=50000,\n",
        "    random_state=42,\n",
        "    stratify=dtr['RENDIMIENTO_GLOBAL']\n",
        ")\n",
        "print(f\"Dataset muestreado: {dtr.shape}\")\n",
        "\n",
        "# ===================================================================\n",
        "# 2. PREPROCESAMIENTO ULTRA-RÁPIDO\n",
        "# ===================================================================\n",
        "def ultra_fast_preprocessing(df_train, df_test):\n",
        "    print(\"⚡ Preprocesamiento ultra-rápido...\")\n",
        "\n",
        "    # Guardar IDs y target\n",
        "    test_ids = df_test['ID'].copy()\n",
        "    y_train = df_train['RENDIMIENTO_GLOBAL'].copy()\n",
        "\n",
        "    # Columnas a eliminar\n",
        "    drop_cols = ['ID', 'FAMI_TIENEINTERNET.1', 'RENDIMIENTO_GLOBAL']\n",
        "    df_train = df_train.drop(drop_cols, axis=1, errors='ignore')\n",
        "    df_test  = df_test.drop(drop_cols, axis=1, errors='ignore')\n",
        "\n",
        "    # 1. Período → SEMESTRE\n",
        "    for df in [df_train, df_test]:\n",
        "        df['SEMESTRE'] = df['PERIODO'].astype(str).str[-1].astype(int)\n",
        "        df.drop('PERIODO', axis=1, inplace=True)\n",
        "\n",
        "    # 2. Suma y desv. estándar de coeficientes\n",
        "    coef_cols = ['coef_1', 'coef_2', 'coef_3', 'coef_4']\n",
        "    for df in [df_train, df_test]:\n",
        "        df['coef_sum'] = df[coef_cols].sum(axis=1)\n",
        "        df['coef_std'] = df[coef_cols].std(axis=1).fillna(0)\n",
        "\n",
        "    # 3. Variables ordinales\n",
        "    horas_map = {\n",
        "        'Menos de 10 horas': 5,\n",
        "        'Entre 11 y 20 horas': 15,\n",
        "        'Entre 21 y 30 horas': 25,\n",
        "        'Más de 30 horas': 35,\n",
        "        '0': 0\n",
        "    }\n",
        "    estrato_map = {\n",
        "        'Estrato 1': 1, 'Estrato 2': 2, 'Estrato 3': 3,\n",
        "        'Estrato 4': 4, 'Estrato 5': 5, 'Estrato 6': 6,\n",
        "        'Sin Estrato': 0, 'No aplica': 0\n",
        "    }\n",
        "    for df in [df_train, df_test]:\n",
        "        df['HORAS_NUM'] = df['ESTU_HORASSEMANATRABAJA'].astype(str)\\\n",
        "                            .map(horas_map).fillna(0)\n",
        "        df['ESTRATO_NUM'] = df['FAMI_ESTRATOVIVIENDA'].astype(str)\\\n",
        "                            .map(estrato_map).fillna(2)\n",
        "\n",
        "    # 4. Variables binarias\n",
        "    binary_cols = ['FAMI_TIENEINTERNET', 'FAMI_TIENECOMPUTADOR', 'FAMI_TIENEAUTOMOVIL']\n",
        "    for col in binary_cols:\n",
        "        for df in [df_train, df_test]:\n",
        "            if col in df.columns:\n",
        "                df[f'{col}_BIN'] = (df[col].astype(str).isin(['Si', 'S'])).astype(int)\n",
        "\n",
        "    # 5. Score socioeconómico\n",
        "    for df in [df_train, df_test]:\n",
        "        df['SOCIO_SCORE'] = (\n",
        "            df['ESTRATO_NUM']\n",
        "            + df.get('FAMI_TIENEAUTOMOVIL_BIN', 0)\n",
        "            + df.get('FAMI_TIENECOMPUTADOR_BIN', 0)\n",
        "        )\n",
        "\n",
        "    # 6. Educación de padres\n",
        "    edu_map = {\n",
        "        'Ninguno': 0, 'No sabe': 0,\n",
        "        'Primaria incompleta': 1, 'Primaria completa': 2,\n",
        "        'Secundaria (Bachillerato) incompleta': 3,\n",
        "        'Secundaria (Bachillerato) completa': 4,\n",
        "        'Técnica o tecnológica incompleta': 5,\n",
        "        'Técnica o tecnológica completa': 6,\n",
        "        'Educación profesional incompleta': 7,\n",
        "        'Educación profesional completa': 8,\n",
        "        'Postgrado': 9\n",
        "    }\n",
        "    for df in [df_train, df_test]:\n",
        "        df['EDU_PADRE'] = df['FAMI_EDUCACIONPADRE'].map(edu_map).fillna(4)\n",
        "        df['EDU_MADRE']  = df['FAMI_EDUCACIONMADRE'].map(edu_map).fillna(4)\n",
        "        df['EDU_MAX']   = df[['EDU_PADRE', 'EDU_MADRE']].max(axis=1)\n",
        "\n",
        "    # Identificar numéricas y categóricas\n",
        "    numeric_cols = [c for c in df_train.columns\n",
        "                    if df_train[c].dtype in ['int64','float64']]\n",
        "    categorical_cols = [c for c in df_train.columns\n",
        "                        if c not in numeric_cols]\n",
        "\n",
        "    print(f\"Procesando {len(numeric_cols)} numéricas y {len(categorical_cols)} categóricas\")\n",
        "\n",
        "    # Imputación numérica\n",
        "    if numeric_cols:\n",
        "        medians = df_train[numeric_cols].median()\n",
        "        df_train[numeric_cols] = df_train[numeric_cols].fillna(medians)\n",
        "        df_test[numeric_cols]  = df_test[numeric_cols].fillna(medians)\n",
        "\n",
        "    # Imputación + LabelEncoding categóricas\n",
        "    for col in categorical_cols:\n",
        "        mode_val = df_train[col].mode().iloc[0] if not df_train[col].mode().empty else 'unknown'\n",
        "        df_train[col] = df_train[col].fillna(mode_val)\n",
        "        df_test[col]  = df_test[col].fillna(mode_val)\n",
        "        le = LabelEncoder()\n",
        "        combined = pd.concat([df_train[col], df_test[col]]).astype(str)\n",
        "        le.fit(combined)\n",
        "        df_train[col] = le.transform(df_train[col].astype(str))\n",
        "        df_test[col]  = le.transform(df_test[col].astype(str))\n",
        "\n",
        "    return df_train.values, df_test.values, y_train, test_ids\n",
        "\n",
        "# Aplicar preprocesamiento\n",
        "X, X_test, y, test_ids = ultra_fast_preprocessing(dtr, dts)\n",
        "print(f\"Features finales: {X.shape[1]}\")\n",
        "\n",
        "# ===================================================================\n",
        "# 3. SPLIT RÁPIDO\n",
        "# ===================================================================\n",
        "print(\"📊 Dividiendo datos en train/val...\")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2,\n",
        "    random_state=42, stratify=y\n",
        ")\n",
        "print(f\"Train: {X_train.shape}, Validation: {X_val.shape}\")\n",
        "\n",
        "# ===================================================================\n",
        "# 4. ENTRENAR LightGBM (sin early stopping en fit)\n",
        "# ===================================================================\n",
        "print(\"🎯 Entrenando LightGBM con parámetros fijos...\")\n",
        "model = LGBMClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=15,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=31,\n",
        "    colsample_bytree=0.8,\n",
        "    subsample=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit simple\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ===================================================================\n",
        "# 5. EVALUACIÓN\n",
        "# ===================================================================\n",
        "print(\"📈 Evaluando en el set de validación...\")\n",
        "y_pred = model.predict(X_val)\n",
        "acc = accuracy_score(y_val, y_pred)\n",
        "print(f\"\\n🎯 ACCURACY (LightGBM): {acc:.4f}\")\n",
        "print(\"\\n📊 Reporte de clasificación:\")\n",
        "print(classification_report(y_val, y_pred, zero_division=0))\n",
        "\n",
        "# ===================================================================\n",
        "# 6. ENTRENAMIENTO FINAL Y PREDICCIONES\n",
        "# ===================================================================\n",
        "print(\"🔄 Reentrenando en todos los datos disponibles...\")\n",
        "X_full = np.vstack([X_train, X_val])\n",
        "y_full = np.hstack([y_train, y_val])\n",
        "model.fit(X_full, y_full)\n",
        "\n",
        "print(\"🎯 Generando predicciones para test...\")\n",
        "preds_test = model.predict(X_test)\n",
        "# ===================================================================\n",
        "# 7. CREAR SUBMISSION\n",
        "# ===================================================================\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'RENDIMIENTO_GLOBAL': preds_test\n",
        "})\n",
        "submission.to_csv('submission_lightgbm.csv', index=False)\n",
        "print(\"✅ Submission creada: submission_lightgbm.csv\")\n",
        "\n",
        "# ===================================================================\n",
        "# 8. IMPORTANCIAS DE FEATURE\n",
        "# ===================================================================\n",
        "print(\"\\n🔝 Top 5 características (LightGBM):\")\n",
        "fi = model.feature_importances_\n",
        "top5 = np.argsort(fi)[-5:][::-1]\n",
        "for i, idx in enumerate(top5, 1):\n",
        "    print(f\"  {i}. Feature {idx} → {fi[idx]}\")\n",
        "\n",
        "print(\"\\n🎉 ¡Todo listo para Kaggle!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZdbF9D80tXd",
        "outputId": "9962ce75-b225-48c2-f51d-50354b6f5610"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 SOLUCIÓN ULTRA-RÁPIDA SABER PRO (LightGBM)\n",
            "==================================================\n",
            "📂 Cargando datos...\n",
            "Dataset original: (692500, 21)\n",
            "⚡ Aplicando muestreo ultra-agresivo...\n",
            "Dataset muestreado: (50000, 21)\n",
            "⚡ Preprocesamiento ultra-rápido...\n",
            "Procesando 16 numéricas y 13 categóricas\n",
            "Features finales: 29\n",
            "📊 Dividiendo datos en train/val...\n",
            "Train: (40000, 29), Validation: (10000, 29)\n",
            "🎯 Entrenando LightGBM con parámetros fijos...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005601 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1726\n",
            "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.371997\n",
            "[LightGBM] [Info] Start training from score -1.387095\n",
            "[LightGBM] [Info] Start training from score -1.395032\n",
            "[LightGBM] [Info] Start training from score -1.391206\n",
            "📈 Evaluando en el set de validación...\n",
            "\n",
            "🎯 ACCURACY (LightGBM): 0.4045\n",
            "\n",
            "📊 Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        alto       0.52      0.61      0.56      2536\n",
            "        bajo       0.42      0.50      0.46      2498\n",
            "  medio-alto       0.30      0.24      0.26      2478\n",
            "  medio-bajo       0.32      0.27      0.29      2488\n",
            "\n",
            "    accuracy                           0.40     10000\n",
            "   macro avg       0.39      0.40      0.39     10000\n",
            "weighted avg       0.39      0.40      0.39     10000\n",
            "\n",
            "🔄 Reentrenando en todos los datos disponibles...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007235 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1732\n",
            "[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.371997\n",
            "[LightGBM] [Info] Start training from score -1.387095\n",
            "[LightGBM] [Info] Start training from score -1.395053\n",
            "[LightGBM] [Info] Start training from score -1.391186\n",
            "🎯 Generando predicciones para test...\n",
            "✅ Submission creada: submission_lightgbm.csv\n",
            "\n",
            "🔝 Top 5 características (LightGBM):\n",
            "  1. Feature 0 → 3327\n",
            "  2. Feature 18 → 2179\n",
            "  3. Feature 14 → 2045\n",
            "  4. Feature 15 → 2023\n",
            "  5. Feature 19 → 1973\n",
            "\n",
            "🎉 ¡Todo listo para Kaggle!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c udea-ai-4-eng-20251-pruebas-saber-pro-colombia -f submission_lightgbm.csv -m 'Solución final con lightGBM'\n"
      ],
      "metadata": {
        "id": "krL_R4jjlzf0",
        "outputId": "fc78caef-ea05-4ce9-8787-32318255003f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 4.06M/4.06M [00:00<00:00, 6.09MB/s]\n",
            "Successfully submitted to UDEA/ai4eng 20251 - Pruebas Saber Pro Colombia"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1x-W2yyq8q1QWgh6eqovWoYwN93PrdQgd",
      "authorship_tag": "ABX9TyO5ynksfHP49TcFe3AJaZGS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}